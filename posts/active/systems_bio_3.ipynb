{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "voluntary-distance",
   "metadata": {},
   "source": [
    "# Systems Biology Lecture 3\n",
    "\n",
    "## Synthetic Biology and Stability Analysis in the Toggle Switch\n",
    "\n",
    "### Topics\n",
    "\n",
    "- $A \\dashv B \\dashv A$ toggle switch\n",
    "- dimensionless equations\n",
    "- stability analysis\n",
    "\n",
    "### Toggle Switch\n",
    "\n",
    "- $A \\dashv B, B \\dashv A$\n",
    "\n",
    "\n",
    "- We can take a boolean approximation where 0 is 'low', 1 is 'high':\n",
    "\n",
    "| A | B | stability |\n",
    "|---|---|----------|\n",
    "| 0 | 0 | unstable |\n",
    "| 0 | 1 | stable   |\n",
    "| 1 | 0 | stable   |\n",
    "| 1 | 1 | unstable |\n",
    "\n",
    "Two dimensions will never produce oscillatory behaviour - this is actually a theorem of Poincare.\n",
    "However, when we do the repressilator, this may come in useful. \n",
    "\n",
    "N.B. this boolean approximation is not rigourous, it is not even often correct! But it can be useful. \n",
    "\n",
    "Suppose we have the following situation:\n",
    "\n",
    "- $A \\dashv B\\text{-gfp} \\dashv A$\n",
    "- $\\text{heat} \\dashv (A \\dashv B)$, which is to say, heat represses the repression, and acts like a 'reset'\n",
    "- $\\text{IPTG} \\dashv (B \\dashv A)$, IPTG is just some small molecule, used in the review\n",
    "\n",
    "\n",
    "To switch from the high $B\\text{-gfp}$ stable state to the $A$ state, we need to add IPTG. \n",
    "\n",
    "\n",
    "This is behaving like a very simple memory module, the cells can 'remember' if it has seen IPTG, and that memory is contained within the $A$ state. Even if the IPTG is removed, the cells will remember that they have seen IPTG and remain in the $A$ state. \n",
    "\n",
    "\n",
    "This toggle switch was constructed using components that had never seen each other before - and was one of the first papers in synthetic biology. \n",
    "\n",
    "\n",
    "### Dimensionless Equations\n",
    "\n",
    "Dimensionless equations are good in that they focus your attention on the essential mathematical features. They are bad in that the connection to experiments can be obscured and the parameters might be harder to interpret. \n",
    "\n",
    "1. $$\\dot{u} = \\frac{\\alpha_1}{1 + v^\\beta} - u$$\n",
    "\n",
    "\n",
    "2. $$\\dot{v} = \\frac{\\alpha_2}{1 + u^\\gamma} - v$$\n",
    "\n",
    "\n",
    "#### Questions\n",
    "\n",
    "1. How does this capture the behaviour of a toggle switch? \n",
    "When $u$ is high, $\\dot{v}$ is small/ negative, and vice versa. \n",
    "\n",
    "2. What are the effective lifetimes (i.e. half-lives) of $u$ and $v$? \n",
    "They are actually the same - this is an assumption made by the paper! We can see this because if you were to ignore the first terms, both are just exponential decay with rate constant of 1, i.e. the same exponential decay for both. If you wanted different rates for both you would need to add another parameter in one of the equations. \n",
    "\n",
    "3. How have the quantities been normalised? \n",
    "Time has been normalised so that 1 unit of time corresponds to the effective lifetime (i.e. decay constant) of $u$ and $v$. Note that we were previously calling this decay constant $\\alpha$, and was governed by $\\alpha_{\\text{deg}}$ and $\\alpha_{\\text{dil}}$. $u$ and $v$ have also been normalised so that $u=1$ corresponds to $K_d$ of $v$ (and vice versa). The $\\alpha$'s have also been fudged by a similar factor. We can see this because what used to be called $K_d$ in Michaelis Mentens/ other contexts is now just 1. \n",
    "\n",
    "4. Which parameters might change if you increase the degredation rate (of both $u$ and $v$)? \n",
    "Both $\\alpha_1$ and $\\alpha_2$ will change. The exponents will not change, they govern the cooperativity. The $\\alpha$'s will actually go down if you increase the degredation rate - you are dividing by a bigger number. \n",
    "\n",
    "#### Plots\n",
    "\n",
    "**Plot some of these graphs!**\n",
    "\n",
    "\n",
    "### Stability Analysis\n",
    "\n",
    "1. Have $\\dot{x} = ax$. When is $x=0$ stable? The answer is iff $a < 0$. \n",
    "Certainly $x=0$ is a fixed point in all these equations. \n",
    "A plot is helpful here! Recall 1a differential equations. Note that for discrete maps, the condition is for $|a| < 1$, but we are looking at a differential equation, not a difference equation. \n",
    "\n",
    "\n",
    "2. In general, we need all of the (real parts of the) eigenvalues of the Hessian matrix to be less than 0. This is described by a vector equation $\\mathbf{\\dot{x}} = \\mathbf{Ax}$, and we need $Re(\\lambda_i) < 0$ for all eigenvalues $\\lambda_i$. \n",
    "\n",
    "**Plot this in two dimensions!**\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "blog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
