{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worthy-clark",
   "metadata": {},
   "source": [
    "# Systems Biology Lecture 2\n",
    "\n",
    "## Autoregulation, Feedback and Bistability\n",
    "\n",
    "- What happens when a gene regulates its own expression?\n",
    "- What are network motifs?\n",
    "- Why might these network motifs evolve?\n",
    "\n",
    "\n",
    "### Autoregulation\n",
    "\n",
    "Two kinds:\n",
    "- positive\n",
    "- negative\n",
    "\n",
    "They do very different things!\n",
    "\n",
    "Negative autoregulation speeds up the \"on time\" and makes the protein concentration more robust to changes in the production rate. Positive autoregulation allows for the possibility of bistability and 'memory'. \n",
    "\n",
    "**Problem**: we want $X \\rightarrow Y$ to happen with an almost digital response. One solution is cooperativity. Another solution is molecular titration. \n",
    "\n",
    "Recall our model from last time:\n",
    "\n",
    "$$XW \\leftrightharpoons X + W, X \\rightarrow Y$$\n",
    "\n",
    "with constants $K_W$, $K_d$. $K_d$ represents the affinity of the transcription factor $X^*$ to the promoter of $Y$, $K_W$ is for the $XW$ complex. These both have units of concentration. \n",
    "\n",
    "#### Questions\n",
    "\n",
    "Under what conditions do we get an ultrasensitive response, where the rate of production of $Y$ is faster than linear w.r.t. $X$?\n",
    "\n",
    "\n",
    "1. $K_d$ vs $K_W$\n",
    "\n",
    "$K_d \\gg K_W$ will mean that $X$ binds to $W$ preferentially before being expressed, and so $Y$ will only be expressed once $X$ is expressed in a threshold above $W_T$ (the total amount of $W$). So we will get a form of ultrasensitivity whereby $Y$ is only activated after a certain threshold, at which point it is produced in reasonable amounts. \n",
    "\n",
    "\n",
    "2. $K_W$ vs $W_T$\n",
    "\n",
    "$K_W \\ll W_T$ will produce an ultrasensitive response because \n",
    "In general, for $X_T < W_T$,\n",
    "\n",
    "$$X \\approx \\frac{X_TK_W}{W_T}$$. \n",
    "\n",
    "Plotting free $X$ vs $X_T$ on a log-log scale, we get a straight line with gradient 1 in the regime above $W_T$, and the same below $W_T$, but with an almost vertical section near $W_T$. \n",
    "\n",
    "**PLOT THESE!**\n",
    "\n",
    "3. $K_d$ vs $W_T$\n",
    "\n",
    "$K_d \\lessapprox W_T$ - \n",
    "\n",
    "\n",
    "### Network Motifs\n",
    "\n",
    "Now we are going to switch tack a little bit. We will look at transcriptional networks, in the context of networks more generally. \n",
    "\n",
    "Given a network with $N$ nodes and $E$ edges (Uri Alon gives an example with 420 nodes and 520 edges), we have $N^2$ many possible directed edges. Let's assign $E$ edges randomly out of the possibilities - this is called an Erdos-Renyi network and will be our null model for a network. (Is this a good null model?! Possibly not...)\n",
    "\n",
    "Let $p = \\frac{E}{N^2}$ be the probability for each edge that it is 'chosen' in our null network. $\\langle N_{\\text{self}} \\rangle = Np = E/N$ (angled brackets mean expectation, just like in quantum mechanics). \n",
    "\n",
    "In Uri's paper, $\\langle N_{\\text{self}} \\rangle$ is on the order of 1.1. However, in his observered transcriptional network, he found about 40 self-directed edges. His observation (with a stats test) is that $42 \\gg 1.1$. Of these, 34 were negative autoregulation, and 6 were positive autoregulation. Uri then asks what possible evolutionary advantages such a network motif might have. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-banner",
   "metadata": {},
   "source": [
    "#### Questions about negative autoregulation\n",
    "\n",
    "1. How does negative autoregulation ($X \\dashv X$) change the response time?\n",
    "It decreases the response time for turning a gene on, but turning a gene off still happens at the 'normal' rate, i.e. at the usual $\\alpha$ rate corresponding to degregation and cell generation rate. Note that changing $\\alpha$ is possible, and does increase sensitivity, but at a significant cost to the cell in that you have to increase the degregation rate somehow - so are expressing and degrading the transcription factor at the same time, which is costly and wasteful. \n",
    "\n",
    "**Plot a graph!**\n",
    "\n",
    "2. How is $X_{\\text{equilibrium}}$ robust to small changes in parameters?\n",
    "It is robust to small changes in $\\alpha$ and $\\beta$; small changes in $\\alpha$ will basically have no effect on the equilibrium concentration of $X$, and the production rate of the protein $\\beta$ also has no effect on the equilibrium value of $X$. \n",
    "\n",
    "**Plot another graph!**\n",
    "\n",
    "Uri makes the argument that these two things are why negative autoregulation are so strongly selected for in nature. \n",
    "\n",
    "#### Positive autoregulation $(X \\rightarrow X)$ and bistability\n",
    "\n",
    "$$\\dot{X} = \\beta_0 + \\beta_1 \\frac{X^n}{K^n + X^n} - \\alpha X$$\n",
    "\n",
    "**plot another graph!**\n",
    "\n",
    "Question: how many fixed points will this function have? You can see from the graph, this will have 3 fixed points - 2 are stable and 1 is unstable. We can draw little arrows on our axes which show which way $X$ is pushed in which regime. These two fixed points are why we call this *bistability*. By changing $\\alpha$ in our equation, we can get a bifurcation, and the number of fixed points is reduced. \n",
    "\n",
    "**Plot another graph! - fold bifurcation**\n",
    "\n",
    "This kind of system displays a primitive kind of memory - if you had seen a high or low degredation in the past then that might tell you what you've seen before. This kind of memory can also be reset, perhaps stochastically. \n",
    "\n",
    "#### Summary \n",
    "\n",
    "We've looked at possible explanations of why autoregulation is observed as frequently as it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recovered-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "blog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
