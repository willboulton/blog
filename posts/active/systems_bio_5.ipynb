{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "moved-business",
   "metadata": {},
   "source": [
    "# Systems Biology Lecture 5\n",
    "\n",
    "## Finishing off last lecture and Graph Properties of Transcription Networks\n",
    "\n",
    "### Topics\n",
    "\n",
    "- Relaxation oscillator with both positive and negative feedback\n",
    "- Robust and tunable oscillations\n",
    "- Barabasi model for power law graphs\n",
    "- Network Motifs: Feed-forward loops\n",
    "\n",
    "### Last Time\n",
    "\n",
    "Last time we saw that there were a couple of problems with our repressilator. Only 40% of the cells oscillated, and the period of oscillation was not particularly tunable. In 1d we saw that it was hard to get oscillations for mathematical reasons, but that oscillations were possible if for example a delay was included. \n",
    "\n",
    "\n",
    "A paper on the topic of tunable oscillations was written by Ferrell at Stanford (Science 2008). He noted that in real life, there were often both positive and negative feedback loops operating within an oscillator. Postive autoregulatory structure was responsible for creating oscillations of a fixed amplitude, whereas the negative feedback parameters governed the period of oscillations. \n",
    "\n",
    "\n",
    "We can see some analogies with electrical circuits; in fact many analogies. And in dynamics, the Van Der Pol oscillator is important as an example of creating limit cycle oscillations. There is another important concept called 'separation of timescales', where some phenomena (like the positive autoregulation) have a very short timescale whereas the negative autoregulation has a very slow timescale. \n",
    "\n",
    "\n",
    "Jeff Hasty at UCSD wrote a paper (Nature 2008) showing how it was in principle possible to get oscillations just using negative autoregulation. \n",
    "\n",
    "### Barabasi Paper: Power Law Distributions in Networks\n",
    "\n",
    "This paper (Barabase & Albert) has like 20,000 citations. \n",
    "They look at networks throughout science, including citation networks, world wide web, social networks, gene regulatory networks, protein interaction networks, ecological networks...\n",
    "The key observation we are trying to explain - some nodes have lots of edges. In particular, $p(k) \\sim k^{-\\alpha}$, where $p$ is the probability for having $k$ edges. \n",
    "\n",
    "Two assumptions:\n",
    "- Growth\n",
    "- Preferential Attachment\n",
    "\n",
    "Let's make a table with our interesting observation:\n",
    "\n",
    "| Nodes | Edges | Directed | $\\alpha$ |\n",
    "|-------|-------|----------|----------|\n",
    "|Webpages| Links |Yes | 2.3 |\n",
    "|Movie stars |co-starring| No| 2.1 |\n",
    "|Articles | citations | Yes | 3 |\n",
    "\n",
    "Barabasi wants to make a model to explain this kind of distribution. \n",
    "\n",
    "Models that clearly do not work:\n",
    "- Erdos-Reyni random network. \n",
    "- \"Small-world\" network (Watts and Strogatz)\n",
    "\n",
    "\n",
    "Power law networks may have this small world property but the converse is not at all true - there are small-world networks which do not exhibit any kind of power law distribution. \n",
    "\n",
    "\n",
    "Barabasi and Albert show that the two assumptions of growth and preferential attachment do lead to a power law distributed network. \n",
    "\n",
    "\n",
    "### Transcriptional Networks\n",
    "\n",
    "- Growth, adding a new gene (e.g. duplication):\n",
    "Suppose $X \\rightarrow X_1, X_2, X_3$, $Y \\rightarrow Y_1, Y_2$. Note that some genes will have about 100 outgoing edges (some TFs control 100 genes) but in general most genes will have an most 2 or 3 incoming edges. \n",
    "\n",
    "- Preferential Attachment:\n",
    "If a random gene (one of the indexed ones) duplicates, along with its promoter/ operator region, then it will have an incoming node coming from $X$ or $Y$ in proportion linearly to the number of edges coming from $X$ and $Y$. \n",
    "\n",
    "\n",
    "### Derivation from paper\n",
    "\n",
    "Start with $m_0$ nodes, and add nodes at a constant linear rate, and add edges at a constant linear rate too. We assume there is preferential attachment. We are going to discretise time $t$. Write some equations:\n",
    "\n",
    "1. $N(t) = m_0 + t$\n",
    "One new node is added at each time step\n",
    "\n",
    "2. $E(t) = mt$\n",
    "At each time point, $m$ edges are attached to the new node. \n",
    "\n",
    "3. $\\Pi(k_i) = \\frac{k_i}{\\sum_{i}k_i}$\n",
    "There is preferential attachment whereby attachment scales linearly w.r.t. the number of edges a node already has. \n",
    "\n",
    "\n",
    "We can make a differential equation in the limit of a large system: \n",
    "\n",
    "$$ \\frac{\\partial k_i}{\\partial t} = \\frac{mk_i}{\\sum k_i} = \\frac{mk_i}{2E(t)} = \\frac{k_i}{2t}$$. \n",
    "\n",
    "\n",
    "We can solve this, the partials don't really matter, and we get that \n",
    "\n",
    "$$k_i(t) = c_i\\sqrt{t}$$. \n",
    "\n",
    "The constant $c_i$ is determined by the boundary condition, which is that $k_i(t_i) = m$, and therefore we get that \n",
    "\n",
    "\n",
    "$$k_i = m\\sqrt{\\frac{t}{t_i}}$$ where $t_i$ is the time step at which the $m$ nodes were added. We can now write down some probabilities:\n",
    "\n",
    "\n",
    "$$\\mathbb{P}(k_i(t) < k) = \\mathbb{P}(t_i > \\frac{m^2t}{k^2}) = 1 - \\frac{m^2t}{k^2(t+m_0)}$$. \n",
    "\n",
    "\n",
    "To get the degree distribution, and taking a limit as $t \\to \\infty$, we get that\n",
    "\n",
    "\n",
    "$$p(k) = \\frac{\\mathbb{P}(k_i(t) < k)}{\\partial k} = \\frac{2m^2t}{k^3(t+m_0)} \\sim \\frac{2m^2}{k^3}$$. \n",
    "\n",
    "\n",
    "We get a power law distribution with exponent $\\alpha = 3$. The authors say that there are ways to get a different exponent, such as using directed edges, but this is not so satisfying. \n",
    "\n",
    "\n",
    "\n",
    "### Null Models of Networks\n",
    "\n",
    "We do not think that an ER network is a particularly good null model of a transcriptional network. What is a good null model?\n",
    "\n",
    "One model might be a degree preserving network. In this, we will take our real network, and then randomise it, in the following way:\n",
    "\n",
    "- turn all the edges into directed edges\n",
    "- pick two edges at random, and swap their targets. \n",
    "- repeat\n",
    "\n",
    "If we do this, the degree distributions of incoming and outgoing edges are identical after this procedure, and this seems to be a pretty good null model. In the next lecture we will look at this, and see if we can identify something like the feed-forward loop network motif. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blog",
   "language": "python",
   "name": "blog"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
